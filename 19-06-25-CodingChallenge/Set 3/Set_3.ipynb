{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Hs5LOBUgnuFL",
        "outputId": "0d60eb60-9397-441d-f0f3-9f200e179ab6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7cd7c828e3d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4e03e7802c56:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Set-3</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Set-3\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 1: Inventory Alerting System**"
      ],
      "metadata": {
        "id": "YILSXngfoNlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the data using PySpark.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = spark.read.csv('/content/drive/MyDrive/inventory_supply.csv',header = True,inferSchema = True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK5uT5rvoPVG",
        "outputId": "40f2cdc3-124a-4ef0-805d-79b64274e650"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create a new column NeedsReorder = StockQty < ReorderLevel .\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"NeedsReorder\", col(\"StockQty\") < col(\"ReorderLevel\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp5m24vzoUlH",
        "outputId": "7b8afb37-3904-4a3b-eb95-ada7c6204968"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|NeedsReorder|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|       false|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|        true|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|       false|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|        true|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|        true|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create a view of all items that need restocking.\n",
        "\n",
        "df_needs_reorder = df.filter(col(\"NeedsReorder\") == True)\n",
        "df_needs_reorder.createOrReplaceTempView(\"items_needing_reorder\")"
      ],
      "metadata": {
        "id": "qBb6h2zioWob"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Highlight warehouses with more than 2 such items.\n",
        "from pyspark.sql.functions import count\n",
        "\n",
        "warehouse_summary = df_needs_reorder.groupBy(\"Warehouse\").agg(count(\"*\").alias(\"NumItemsNeedingReorder\")).filter(col(\"NumItemsNeedingReorder\") > 2)\n",
        "warehouse_summary.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufrs9dbEoYu9",
        "outputId": "b5859564-364b-4121-a040-92ca6a5c1e4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------------+\n",
            "|Warehouse|NumItemsNeedingReorder|\n",
            "+---------+----------------------+\n",
            "+---------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 2: Supplier Price Optimization**"
      ],
      "metadata": {
        "id": "leP7KTZHphrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Group items by Supplier and compute average price.\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "category_avg = df.groupBy(\"Category\").agg(avg(\"UnitPrice\").alias(\"AvgPriceByCategory\"))\n",
        "category_avg.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyKgWJFXpw4D",
        "outputId": "90840409-c2bb-49db-f524-33ce1a1f1f8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|   Category|AvgPriceByCategory|\n",
            "+-----------+------------------+\n",
            "|Electronics|           36000.0|\n",
            "|  Furniture|            6000.0|\n",
            "| Appliances|           25000.0|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Find which suppliers offer items below average price in their category.\n",
        "df_with_avg = df.join(category_avg, on=\"Category\", how=\"left\")\n",
        "\n",
        "df_below_avg = df_with_avg.filter(df_with_avg[\"UnitPrice\"] < df_with_avg[\"AvgPriceByCategory\"])\n",
        "df_below_avg.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFRQ9Ig5p0Im",
        "outputId": "16d4d67f-3250-4737-f61f-a5c8fc33f5fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+--------+----------+--------+------------+-------------+---------+---------+------------+------------------+\n",
            "|   Category|ItemID|ItemName| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|NeedsReorder|AvgPriceByCategory|\n",
            "+-----------+------+--------+----------+--------+------------+-------------+---------+---------+------------+------------------+\n",
            "|Electronics|  I001|  LED TV|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|       false|           36000.0|\n",
            "|Electronics|  I005| Printer|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|        true|           36000.0|\n",
            "+-----------+------+--------+----------+--------+------------+-------------+---------+---------+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Tag suppliers with Good Deal if >50% of their items are below market average.\n",
        "from pyspark.sql.functions import count, when, lit\n",
        "\n",
        "total_items = df.groupBy(\"Supplier\").agg(count(\"*\").alias(\"TotalItems\"))\n",
        "below_avg_items = df_below_avg.groupBy(\"Supplier\").agg(count(\"*\").alias(\"BelowAvgItems\"))\n",
        "\n",
        "supplier_deals = total_items.join(below_avg_items, on=\"Supplier\", how=\"left\").fillna(0, subset=[\"BelowAvgItems\"])\\\n",
        ".withColumn(\"GoodDeal\", (col(\"BelowAvgItems\") / col(\"TotalItems\")) > 0.5)\n",
        "\n",
        "supplier_deals.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9cr8Pvhp2N0",
        "outputId": "8a47b447-feda-4563-a153-3d2caaab4083"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+-------------+--------+\n",
            "| Supplier|TotalItems|BelowAvgItems|GoodDeal|\n",
            "+---------+----------+-------------+--------+\n",
            "|   AVTech|         1|            1|    true|\n",
            "|TechWorld|         1|            0|   false|\n",
            "|PrintFast|         1|            1|    true|\n",
            "| FreezeIt|         1|            0|   false|\n",
            "|  ChairCo|         1|            0|   false|\n",
            "+---------+----------+-------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 3: Cost Forecasting**"
      ],
      "metadata": {
        "id": "tSGNBhTvqznF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calculate TotalStockValue = StockQty * UnitPrice .\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"TotalStockValue\", col(\"StockQty\") * col(\"UnitPrice\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0RqQmSbq1Hr",
        "outputId": "3b6ab172-003b-444a-f519-ede8e501da2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|NeedsReorder|TotalStockValue|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|       false|        1500000|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|        true|         700000|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|       false|         240000|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|        true|         125000|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|        true|          24000|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Identify top 3 highest-value items.\n",
        "\n",
        "top_3_items = df.orderBy(col(\"TotalStockValue\").desc()).limit(3)\n",
        "top_3_items.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu406m4Sreoh",
        "outputId": "9631b2ec-88c7-410b-8a05-faa0d110f2eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|NeedsReorder|TotalStockValue|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|       false|        1500000|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|        true|         700000|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|       false|         240000|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Export the result as a Parquet file partitioned by Warehouse .\n",
        "\n",
        "top_3_items.write.mode(\"overwrite\").partitionBy(\"Warehouse\").parquet(\"/content/drive/MyDrive/top3_high_value_items\")"
      ],
      "metadata": {
        "id": "z1gKsCC4rgH0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 4: Warehouse Utilization**"
      ],
      "metadata": {
        "id": "CUqcXOW0ssSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Count items stored per warehouse.\n",
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "items_per_warehouse = df.groupBy(\"Warehouse\").agg(countDistinct(\"ItemID\").alias(\"NumItems\"))\n",
        "items_per_warehouse.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIjfTaM_scW1",
        "outputId": "91ec6496-620e-4fd4-af5b-28a106bd955a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+\n",
            "| Warehouse|NumItems|\n",
            "+----------+--------+\n",
            "|WarehouseA|       2|\n",
            "|WarehouseC|       1|\n",
            "|WarehouseB|       2|\n",
            "+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Average stock per category in each warehouse.\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "avg_stock = df.groupBy(\"Warehouse\", \"Category\").agg(avg(\"StockQty\").alias(\"AvgStockPerCategory\"))\n",
        "avg_stock.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0WcEoeCsyAF",
        "outputId": "18da0c91-4521-4b3e-a1ba-055358b6fa7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-------------------+\n",
            "| Warehouse|   Category|AvgStockPerCategory|\n",
            "+----------+-----------+-------------------+\n",
            "|WarehouseB|Electronics|                6.5|\n",
            "|WarehouseA|  Furniture|               40.0|\n",
            "|WarehouseC| Appliances|                5.0|\n",
            "|WarehouseA|Electronics|               50.0|\n",
            "+----------+-----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Determine underutilized warehouses ( total stock < 100 ).\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "warehouse_stock = df.groupBy(\"Warehouse\").agg(sum(\"StockQty\").alias(\"TotalStock\"))\n",
        "\n",
        "underutilized = warehouse_stock.filter(col(\"TotalStock\") < 100)\n",
        "underutilized.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHXUyVuOs0M0",
        "outputId": "b4a8e51d-d092-4b9a-fa0a-d5952b950b36"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "| Warehouse|TotalStock|\n",
            "+----------+----------+\n",
            "|WarehouseA|        90|\n",
            "|WarehouseC|         5|\n",
            "|WarehouseB|        13|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 5: Delta Audit Trail**"
      ],
      "metadata": {
        "id": "vTsCnBWiuXCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Save as Delta table retail_inventory .\n",
        "# 2. Update stock of 'Laptop' to 20.\n",
        "# 3. Delete any item with StockQty = 0 .\n",
        "# 4. Run DESCRIBE HISTORY and query VERSION AS OF previous state.\n",
        "\n",
        "df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/retail_inventory\")\n",
        "\n",
        "spark.sql(\"DROP TABLE IF EXISTS retail_inventory\")\n",
        "spark.sql(\"CREATE TABLE retail_inventory USING DELTA LOCATION '/delta/retail_inventory'\")\n",
        "\n",
        "from delta.tables import DeltaTable\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "delta_table = DeltaTable.forPath(spark, \"/delta/retail_inventory\")\n",
        "\n",
        "delta_table.update(\n",
        "    condition = col(\"ItemName\") == \"Laptop\",\n",
        "    set = { \"StockQty\": lit(20) }\n",
        ")\n",
        "\n",
        "delta_table.delete(col(\"StockQty\") == 0)\n",
        "\n",
        "spark.sql(\"DESCRIBE HISTORY retail_inventory\").show(truncate=False)"
      ],
      "metadata": {
        "id": "_P5X01ZtubFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 6: Alerts from Restock Logs (Join Task)**"
      ],
      "metadata": {
        "id": "zc7Dmj2muwF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Join with inventory table to update StockQty.\n",
        "restock_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/content/drive/MyDrive/restock_logs.csv\")\n",
        "\n",
        "from pyspark.sql.functions import to_date\n",
        "restock_df = restock_df.withColumn(\"RestockDate\", to_date(\"RestockDate\", \"yyyy-MM-dd\"))\n",
        "restock_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9tcFwyku0Op",
        "outputId": "4a8d2eb6-55f3-492e-f05f-3c6e7e92e775"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+-------------+\n",
            "|ItemID|RestockDate|QuantityAdded|\n",
            "+------+-----------+-------------+\n",
            "|  I002| 2024-04-20|           10|\n",
            "|  I005| 2024-04-22|            5|\n",
            "|  I001| 2024-04-25|           20|\n",
            "+------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Calculate new stock and flag RestockedRecently = true for updated items.\n",
        "# Join with base Delta inventory\n",
        "inventory_df = spark.read.format(\"delta\").load(\"/delta/retail_inventory\")\n",
        "\n",
        "restocked_df = restock_df.join(inventory_df, on=\"ItemID\", how=\"inner\") \\\n",
        "    .withColumn(\"NewStockQty\", col(\"StockQty\") + col(\"QuantityAdded\")) \\\n",
        "    .withColumn(\"RestockedRecently\", lit(True)) \\\n",
        "    .select(\"ItemID\", \"NewStockQty\", \"RestockedRecently\")"
      ],
      "metadata": {
        "id": "fompP5kaveRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Use MERGE INTO to update in Delta.\n",
        "from delta.tables import DeltaTable\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "delta_table = DeltaTable.forPath(spark, \"/delta/retail_inventory\")\n",
        "\n",
        "delta_table.alias(\"tgt\").merge(\n",
        "    restocked_df.alias(\"src\"),\n",
        "    \"tgt.ItemID = src.ItemID\"\n",
        ").whenMatchedUpdate(set={\n",
        "    \"StockQty\": col(\"src.NewStockQty\"),\n",
        "    \"RestockedRecently\": col(\"src.RestockedRecently\")\n",
        "}).execute()"
      ],
      "metadata": {
        "id": "PEVDkxt3vf8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 7: Report Generation with SQL Views**"
      ],
      "metadata": {
        "id": "-r-oh4DnwROB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create SQL view inventory_summary with:\n",
        "# ItemName, Category, StockQty, NeedsReorder, TotalStockValue\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"NeedsReorder\", col(\"StockQty\") < col(\"ReorderLevel\")).withColumn(\"TotalStockValue\", col(\"StockQty\") * col(\"UnitPrice\"))\n",
        "df.createOrReplaceTempView(\"inventory_summary\")"
      ],
      "metadata": {
        "id": "1JUXlafxwSxt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create view supplier_leaderboard sorted by average price\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW supplier_leaderboard AS\n",
        "    SELECT Supplier, ROUND(AVG(UnitPrice), 2) AS AvgUnitPrice\n",
        "    FROM inventory_summary\n",
        "    GROUP BY Supplier\n",
        "    ORDER BY AvgUnitPrice ASC\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM supplier_leaderboard\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfe40eucxmS_",
        "outputId": "32c025d7-361a-4eff-9041-2c056808c263"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+\n",
            "| Supplier|AvgUnitPrice|\n",
            "+---------+------------+\n",
            "|  ChairCo|      6000.0|\n",
            "|PrintFast|      8000.0|\n",
            "| FreezeIt|     25000.0|\n",
            "|   AVTech|     30000.0|\n",
            "|TechWorld|     70000.0|\n",
            "+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 8: Advanced Filtering**"
      ],
      "metadata": {
        "id": "HmRiRny3x2Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Use when / otherwise to categorize items:\n",
        "# \"Overstocked\" (>2x ReorderLevel)\n",
        "# \"LowStock\"\n",
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "df = df.withColumn(\"StockStatus\",when(col(\"StockQty\") > 2 * col(\"ReorderLevel\"), \"Overstocked\").otherwise(\"LowStock\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-MxGp0bx6Ey",
        "outputId": "691ea818-3d3e-444f-b0d6-32efbf3aec1d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|NeedsReorder|TotalStockValue|StockStatus|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|       false|        1500000|Overstocked|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|        true|         700000|   LowStock|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|       false|         240000|Overstocked|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|        true|         125000|   LowStock|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|        true|          24000|   LowStock|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Use .filter() and .where() for the same and compare.\n",
        "\n",
        "overstocked_filter = df.filter(col(\"StockStatus\") == \"Overstocked\")\n",
        "overstocked_filter.show()\n",
        "\n",
        "overstocked_where = df.where(\"StockStatus = 'Overstocked'\")\n",
        "overstocked_where.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkROM6pHyDbq",
        "outputId": "b006506c-0bbf-4fdc-fe31-69a8eb51df38"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+------------+---------------+-----------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice|Supplier|NeedsReorder|TotalStockValue|StockStatus|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+------------+---------------+-----------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|  AVTech|       false|        1500000|Overstocked|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000| ChairCo|       false|         240000|Overstocked|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+------------+---------------+-----------+\n",
            "\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+------------+---------------+-----------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice|Supplier|NeedsReorder|TotalStockValue|StockStatus|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+------------+---------------+-----------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|  AVTech|       false|        1500000|Overstocked|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000| ChairCo|       false|         240000|Overstocked|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+------------+---------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 9: Feature Engineering**"
      ],
      "metadata": {
        "id": "edOyPhMEyxnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Extract RestockMonth from LastRestocked .\n",
        "from pyspark.sql.functions import month\n",
        "\n",
        "df = df.withColumn(\"RestockMonth\", month(\"LastRestocked\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvOiTJbLyzMa",
        "outputId": "16ab70a7-9eda-4ed0-8a33-8914428569a3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|NeedsReorder|TotalStockValue|StockStatus|RestockMonth|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|       false|        1500000|Overstocked|           3|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|        true|         700000|   LowStock|           4|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|       false|         240000|Overstocked|           3|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|        true|         125000|   LowStock|           2|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|        true|          24000|   LowStock|           3|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create feature: StockAge = CURRENT_DATE - LastRestocked\n",
        "from pyspark.sql.functions import current_date, datediff\n",
        "\n",
        "df = df.withColumn(\"StockAge\", datediff(current_date(), \"LastRestocked\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsjVwR7HzC4E",
        "outputId": "f902d7d4-1491-4a9f-bb82-351a36d0bb29"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+--------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|NeedsReorder|TotalStockValue|StockStatus|RestockMonth|StockAge|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+--------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|       false|        1500000|Overstocked|           3|     461|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|        true|         700000|   LowStock|           4|     444|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|       false|         240000|Overstocked|           3|     451|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|        true|         125000|   LowStock|           2|     485|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|        true|          24000|   LowStock|           3|     446|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Bucket StockAge into: New, Moderate, Stale\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"StockAgeBucket\",\n",
        "    when(col(\"StockAge\") <= 30, \"New\")\n",
        "    .when(col(\"StockAge\") <= 90, \"Moderate\")\n",
        "    .otherwise(\"Stale\")\n",
        ")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIFyzmZDzE5a",
        "outputId": "d76fac72-981f-4c4f-9bef-d94a1de6abb6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+--------+--------------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|NeedsReorder|TotalStockValue|StockStatus|RestockMonth|StockAge|StockAgeBucket|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+--------+--------------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|       false|        1500000|Overstocked|           3|     461|         Stale|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|        true|         700000|   LowStock|           4|     444|         Stale|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|       false|         240000|Overstocked|           3|     451|         Stale|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|        true|         125000|   LowStock|           2|     485|         Stale|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|        true|          24000|   LowStock|           3|     446|         Stale|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+------------+---------------+-----------+------------+--------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 10: Export Options**"
      ],
      "metadata": {
        "id": "WvCR0U5WzcDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export full DataFrame to CSV for analysts\n",
        "df.write.mode(\"overwrite\").option(\"header\", True).csv(\"/export/inventory/full_dataset/csv/\")\n",
        "\n",
        "# Export to JSON for integration needs\n",
        "df.write.mode(\"overwrite\").json(\"/export/inventory/full_dataset/json/\")\n",
        "\n",
        "# Export as Delta for downstream pipelines\n",
        "df.write.format(\"delta\").mode(\"overwrite\").save(\"/export/inventory/full_dataset/delta/\")"
      ],
      "metadata": {
        "id": "BTBATlA6zddb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}