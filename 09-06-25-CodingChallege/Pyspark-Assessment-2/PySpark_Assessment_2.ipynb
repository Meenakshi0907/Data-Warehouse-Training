{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "4Rupvmit8L2P",
        "outputId": "f908ae3b-c92d-4f20-aee5-431bd07caf3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7af71d793210>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://30af322fce86:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PysparkAssessment2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        ".appName(\"PysparkAssessment2\")\\\n",
        ".getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingestion & Exploration\n",
        "# Read all 3 files (CSV + JSON) using PySpark.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "employees_df = spark.read.csv('/content/drive/MyDrive/employees.csv',header= True,inferSchema=True)\n",
        "attendance_df = spark.read.csv('/content/drive/MyDrive/attendance.csv',header= True,inferSchema=True)\n",
        "bonuses_df = spark.read.option(\"multiline\", True).json('/content/drive/MyDrive/bonuses.json')\n",
        "\n",
        "employees_df.show(5)\n",
        "attendance_df.show(5)\n",
        "bonuses_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZK7umO_87bD",
        "outputId": "7a05e94b-a3f2-4bba-f94c-dc4d6cc756cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "\n",
            "+-----+----------+-------+\n",
            "|EmpID|      Date| Status|\n",
            "+-----+----------+-------+\n",
            "|    1|2024-04-01|Present|\n",
            "|    1|2024-04-02|Present|\n",
            "|    2|2024-04-01| Absent|\n",
            "|    2|2024-04-02|Present|\n",
            "|    3|2024-04-01|Present|\n",
            "+-----+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----+-----+----+\n",
            "|Bonus|EmpID|Year|\n",
            "+-----+-----+----+\n",
            "| 5000|    1|2023|\n",
            "| 7000|    2|2023|\n",
            "| 6500|    3|2023|\n",
            "| 6000|    4|2023|\n",
            "| 4000|    5|2023|\n",
            "+-----+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show schemas and sample records.\n",
        "\n",
        "print(\"Employees Schema:\")\n",
        "employees_df.printSchema()\n",
        "\n",
        "print(\"Attendance Schema:\")\n",
        "attendance_df.printSchema()\n",
        "\n",
        "print(\"Bonuses Schema:\")\n",
        "bonuses_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jBZQBpE9R8M",
        "outputId": "1f1662a3-ed66-44df-960e-f36bd476be1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employees Schema:\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- JoinDate: date (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            " |-- ManagerID: integer (nullable = true)\n",
            "\n",
            "Attendance Schema:\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Status: string (nullable = true)\n",
            "\n",
            "Bonuses Schema:\n",
            "root\n",
            " |-- Bonus: long (nullable = true)\n",
            " |-- EmpID: long (nullable = true)\n",
            " |-- Year: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame Operations\n",
        "# Add a column TenureYears using datediff() and round() .\n",
        "\n",
        "from pyspark.sql.functions import date_diff, current_date,round\n",
        "\n",
        "employees_df = employees_df.withColumn(\"TenureYears\",round(date_diff(current_date(),employees_df['JoinDate'])/365.0,1))\n",
        "employees_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoaMH8rk9WJg",
        "outputId": "4a1c5ea6-02e6-46b6-8607-ef0262fff179"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TotalCompensation = Salary + Bonus .\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "emp_bonus = employees_df.join(bonuses_df,on = 'EmpID')\n",
        "\n",
        "emp_bonus = emp_bonus.withColumn(\"TotalCompention\",col(\"Salary\") + col(\"Bonus\"))\n",
        "emp_bonus.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvHkZKw59bM7",
        "outputId": "bb79b185-313b-431a-ffbb-f1be3237db0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompention|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|          60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|          87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|          81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|          66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|          54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter employees with more than 2 years in the company.\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "exp_emp = emp_bonus.filter(col(\"TenureYears\") > 2)\n",
        "exp_emp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqrwvekL9fJA",
        "outputId": "e0aff7cb-fdd9-4d1f-eb2b-592b0381302d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompention|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|          60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|          87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|          81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|          66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|          54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show employees who report to a manager ( ManagerID is not null ).\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "report_manager = emp_bonus.filter(col(\"ManagerID\").isNotNull())\n",
        "report_manager.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FgTQU7e9mBB",
        "outputId": "47f8e983-ec90-447d-ca52-62e7a63e09e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompention|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|          87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|          81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|          66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|          54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation\n",
        "# Average salary per department.\n",
        "\n",
        "from pyspark.sql.functions import avg,col\n",
        "\n",
        "avg_dept = employees_df.groupBy(\"Department\").agg(avg(col(\"Salary\")))\n",
        "avg_dept.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgJLau64-NvC",
        "outputId": "253b934d-39e8-4a0d-cb0b-9b5ec4d76402"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "| Department|avg(Salary)|\n",
            "+-----------+-----------+\n",
            "|Engineering|    77500.0|\n",
            "|         HR|    52500.0|\n",
            "|  Marketing|    60000.0|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of employees under each manager.\n",
        "\n",
        "from pyspark.sql.functions import count\n",
        "\n",
        "no_emp_manager = employees_df.groupBy(\"ManagerID\").agg(count(\"EmpID\"))\n",
        "no_emp_manager.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-EN8WWt-7O_",
        "outputId": "3ba9249b-a9a9-497a-b2f8-ffe2c95ae837"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+\n",
            "|ManagerID|count(EmpID)|\n",
            "+---------+------------+\n",
            "|     NULL|           1|\n",
            "|        1|           4|\n",
            "+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of absences per employee.\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "absences_df = attendance_df.filter(col(\"Status\") == \"Absent\").groupBy(\"EmpID\").agg(count(\"*\").alias(\"AbsenceCount\"))\n",
        "absences_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCf1i8nbACzz",
        "outputId": "cafa4a1e-68e6-42fe-9069-2525423e9f39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+\n",
            "|EmpID|AbsenceCount|\n",
            "+-----+------------+\n",
            "|    4|           2|\n",
            "|    2|           1|\n",
            "+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joins\n",
        "# Join employees and attendance → Get attendance % (Present days / Total days).\n",
        "\n",
        "from pyspark.sql.functions import count, when, col, round\n",
        "\n",
        "total_days_df = attendance_df.groupBy(\"EmpID\").agg(count(\"*\").alias(\"TotalDays\"))\n",
        "\n",
        "present_days_df = attendance_df.filter(col(\"Status\") == \"Present\").groupBy(\"EmpID\").agg(count(\"*\").alias(\"PresentDays\"))\n",
        "\n",
        "attendance_summary_df = employees_df.join(total_days_df, \"EmpID\").join(present_days_df, \"EmpID\", \"left\").fillna(0, subset=[\"PresentDays\"]) \\\n",
        "    .withColumn(\"AttendancePct\", round((col(\"PresentDays\") / col(\"TotalDays\")) * 100, 2))\n",
        "\n",
        "attendance_summary_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I934OnZJAiiw",
        "outputId": "ab35e65d-1828-4d05-8d18-fdefa9460751"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+---------+-----------+-------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|TotalDays|PresentDays|AttendancePct|\n",
            "+-----+------+-----------+----------+------+---------+-----------+---------+-----------+-------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|        2|          2|        100.0|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|        2|          1|         50.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|        2|          2|        100.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|        2|          0|          0.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|        2|          2|        100.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+---------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join employees and bonuses → Show top 3 employees by TotalCompensation.\n",
        "\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "comp_df = employees_df.join(bonuses_df, \"EmpID\", \"left\").withColumn(\"TotalCompensation\", col(\"Salary\") + col(\"Bonus\"))\n",
        "\n",
        "top_3_earners = comp_df.orderBy(desc(\"TotalCompensation\")).select(\"EmpID\", \"Name\", \"Department\", \"TotalCompensation\").limit(3)\n",
        "\n",
        "top_3_earners.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u04onp8ABU_7",
        "outputId": "859de81d-3768-4936-80b9-e0272f3a8b59"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+-----------------+\n",
            "|EmpID|  Name| Department|TotalCompensation|\n",
            "+-----+------+-----------+-----------------+\n",
            "|    2|   Raj|Engineering|            87000|\n",
            "|    3|Simran|Engineering|            81500|\n",
            "|    4| Aamir|  Marketing|            66000|\n",
            "+-----+------+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-level join: employees + bonuses + attendance .\n",
        "# Join all three datasets\n",
        "multi_join_df = employees_df .join(bonuses_df, \"EmpID\", \"left\").join(attendance_df, \"EmpID\", \"left\")\n",
        "\n",
        "multi_join_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsQnjDgABhNZ",
        "outputId": "e94f8559-a2ea-461d-f945-f6ac4470b8d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+----------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|      Date| Status|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+----------+-------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|2024-04-02|Present|\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1| 5000|2023|2024-04-01|Present|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|2024-04-02|Present|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|2024-04-01| Absent|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|2024-04-02|Present|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|2024-04-01|Present|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|2024-04-02| Absent|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|2024-04-01| Absent|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|2024-04-02|Present|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4| 4000|2023|2024-04-01|Present|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# String & Date Functions\n",
        "# Extract year and month from JoinDate\n",
        "\n",
        "from pyspark.sql.functions import year, month\n",
        "\n",
        "employees_df = employees_df.withColumn(\"JoinYear\", year(\"JoinDate\")).withColumn(\"JoinMonth\", month(\"JoinDate\"))\n",
        "\n",
        "employees_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_Nl91z5Bw4Z",
        "outputId": "29a3f80b-04a2-46e2-ba82-b4d9e2b50ae5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|    2021|        5|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|    2020|        3|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|    2022|        7|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|    2019|       11|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|    2023|        1|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask employee names using regex.\n",
        "\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "employees_df = employees_df.withColumn(\"MaskedName\",\n",
        "    regexp_replace(\"Name\", \"(?<=^.).\", \"*\"))\n",
        "\n",
        "employees_df.select(\"EmpID\", \"Name\", \"MaskedName\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcHcLrYhCQpb",
        "outputId": "b815b52c-d7ce-4ffc-e5c3-8686d89edc6d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+\n",
            "|EmpID|  Name|MaskedName|\n",
            "+-----+------+----------+\n",
            "|    1| Anita|     A*ita|\n",
            "|    2|   Raj|       R*j|\n",
            "|    3|Simran|    S*mran|\n",
            "|    4| Aamir|     A*mir|\n",
            "|    5| Nisha|     N*sha|\n",
            "+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use substring() to create EmpCode like \"EMP001\".\n",
        "\n",
        "from pyspark.sql.functions import lpad, concat, lit\n",
        "\n",
        "employees_df = employees_df.withColumn(\"EmpCode\", concat(lit(\"EMP\"), lpad(col(\"EmpID\").cast(\"string\"), 3, \"0\")))\n",
        "\n",
        "employees_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaNT7WC8CUyM",
        "outputId": "1434b96c-a076-487b-8070-82a3b221f398"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|    2021|        5|     A*ita| EMP001|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|    2020|        3|       R*j| EMP002|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|    2022|        7|    S*mran| EMP003|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|    2019|       11|     A*mir| EMP004|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|    2023|        1|     N*sha| EMP005|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional & Null Handling\n",
        "# Use when/otherwise to label performance:\n",
        "# “High” if Bonus > 6000\n",
        "# “Medium” if 4000–6000\n",
        "# “Low” otherwise\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "employees_df = employees_df.join(bonuses_df, on=\"EmpID\", how=\"left\")\n",
        "\n",
        "employees_df = employees_df.withColumn(\n",
        "    \"Performance\",\n",
        "    when(col(\"Bonus\") > 6000, \"High\")\n",
        "    .when((col(\"Bonus\") >= 4000) & (col(\"Bonus\") <= 6000), \"Medium\")\n",
        "    .otherwise(\"Low\")\n",
        ")\n",
        "\n",
        "employees_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlXLopjWCxgj",
        "outputId": "25470d87-bb96-4bc2-ef1b-0154dbd350ec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+-----+----+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|Bonus|Year|Performance|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+-----+----+-----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|    2021|        5|     A*ita| EMP001| 5000|2023|     Medium|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|    2020|        3|       R*j| EMP002| 7000|2023|       High|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|    2022|        7|    S*mran| EMP003| 6500|2023|       High|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|    2019|       11|     A*mir| EMP004| 6000|2023|     Medium|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|    2023|        1|     N*sha| EMP005| 4000|2023|     Medium|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+-----+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing ManagerID using fillna(\"No Manager\") .\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "employees_df = employees_df.withColumn(\"ManagerID\", col(\"ManagerID\").cast(\"string\"))\n",
        "employees_df = employees_df.fillna({\"ManagerID\": \"No Manager\"})\n",
        "employees_df.select(\"EmpID\", \"Name\", \"ManagerID\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyF6K5nLDS5J",
        "outputId": "06482030-d19a-4b62-b189-38575ee7a695"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+\n",
            "|EmpID|  Name| ManagerID|\n",
            "+-----+------+----------+\n",
            "|    1| Anita|No Manager|\n",
            "|    2|   Raj|         1|\n",
            "|    3|Simran|         1|\n",
            "|    4| Aamir|         1|\n",
            "|    5| Nisha|         1|\n",
            "+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark SQL\n",
        "# Create and use database hr .\n",
        "spark.sql(\"Create database hr\")\n",
        "spark.sql(\"use hr\")\n",
        "\n",
        "# Save all DataFrames as tables: employees , attendance , bonuses .\n",
        "employees_df.write.mode(\"overwrite\").saveAsTable(\"employees\")\n",
        "attendance_df.write.mode(\"overwrite\").saveAsTable(\"attendance\")\n",
        "bonuses_df.write.mode(\"overwrite\").saveAsTable(\"bonuses\")"
      ],
      "metadata": {
        "id": "XqqtRSH4DjgZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write SQL queries:\n",
        "# Top paid employee in each department.\n",
        "spark.sql(\"\"\"\n",
        "SELECT e.Department, e.Name, e.Salary\n",
        "FROM employees e\n",
        "JOIN (\n",
        "    SELECT Department, MAX(Salary) as MaxSalary\n",
        "    FROM employees\n",
        "    GROUP BY Department\n",
        ") max_salaries\n",
        "ON e.Department = max_salaries.Department AND e.Salary = max_salaries.MaxSalary\n",
        "\"\"\").show()\n",
        "\n",
        "# Attendance rate by department.\n",
        "spark.sql(\"DROP VIEW IF EXISTS attendance_summary\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW attendance_summary AS\n",
        "    SELECT a.EmpID,\n",
        "           e.Department,\n",
        "           COUNT(*) AS TotalDays,\n",
        "           SUM(CASE WHEN a.Status = 'Present' THEN 1 ELSE 0 END) AS PresentDays\n",
        "    FROM attendance a\n",
        "    JOIN employees e ON a.EmpID = e.EmpID\n",
        "    GROUP BY a.EmpID, e.Department\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Department,\n",
        "           ROUND(SUM(PresentDays)*100.0 / SUM(TotalDays), 2) AS AttendanceRatePct\n",
        "    FROM attendance_summary\n",
        "    GROUP BY Department\n",
        "\"\"\").show()\n",
        "\n",
        "# Employees joined after 2021 with salary > 70,000.\n",
        "spark.sql(\"\"\"\n",
        "SELECT EmpID, Name, Department, JoinDate, Salary\n",
        "FROM employees\n",
        "WHERE JoinDate > '2021-12-31' AND Salary > 70000\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tB0zV_dDrv-",
        "outputId": "08a4fd8d-e535-41da-87b1-e15cd779c1ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+------+\n",
            "| Department| Name|Salary|\n",
            "+-----------+-----+------+\n",
            "|         HR|Anita| 55000|\n",
            "|Engineering|  Raj| 80000|\n",
            "|  Marketing|Aamir| 60000|\n",
            "+-----------+-----+------+\n",
            "\n",
            "+-----------+-----------------+\n",
            "| Department|AttendanceRatePct|\n",
            "+-----------+-----------------+\n",
            "|Engineering|            75.00|\n",
            "|         HR|           100.00|\n",
            "|  Marketing|             0.00|\n",
            "+-----------+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|\n",
            "+-----+------+-----------+----------+------+\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|\n",
            "+-----+------+-----------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced (Optional)\n",
        "# Use a UDF to classify department as \"Tech\" vs \"Non-Tech\".\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def classify_department(dept):\n",
        "    return \"Tech\" if dept.lower() in [\"engineering\", \"it\", \"development\"] else \"Non-Tech\"\n",
        "\n",
        "classify_udf = udf(classify_department, StringType())\n",
        "employees_df = employees_df.withColumn(\"DeptType\", classify_udf(\"Department\"))\n",
        "employees_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv1h4j0wFRkx",
        "outputId": "a7b65691-8efb-4d35-f9a3-476be9c7c48a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+----------+-----------+--------+---------+----------+-------+-----+----+-----------+--------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary| ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|Bonus|Year|Performance|DeptType|\n",
            "+-----+------+-----------+----------+------+----------+-----------+--------+---------+----------+-------+-----+----+-----------+--------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|No Manager|        4.1|    2021|        5|     A*ita| EMP001| 5000|2023|     Medium|Non-Tech|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|         1|        5.2|    2020|        3|       R*j| EMP002| 7000|2023|       High|    Tech|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|         1|        2.9|    2022|        7|    S*mran| EMP003| 6500|2023|       High|    Tech|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|         1|        5.6|    2019|       11|     A*mir| EMP004| 6000|2023|     Medium|Non-Tech|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|         1|        2.4|    2023|        1|     N*sha| EMP005| 4000|2023|     Medium|Non-Tech|\n",
            "+-----+------+-----------+----------+------+----------+-----------+--------+---------+----------+-------+-----+----+-----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a view emp_attendance_summary .\n",
        "from pyspark.sql.functions import count, sum, when\n",
        "\n",
        "# Create attendance summary DataFrame\n",
        "emp_attendance_summary = attendance_df.join(employees_df, \"EmpID\") \\\n",
        "    .groupBy(\"EmpID\", \"Name\", \"Department\") \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"TotalDays\"),\n",
        "        sum(when(col(\"Status\") == \"Present\", 1).otherwise(0)).alias(\"PresentDays\")\n",
        "    ) \\\n",
        "    .withColumn(\"AttendanceRate\", round((col(\"PresentDays\") / col(\"TotalDays\")) * 100, 2))\n",
        "\n",
        "emp_attendance_summary.createOrReplaceTempView(\"emp_attendance_summary\")\n",
        "spark.sql(\"SELECT * FROM emp_attendance_summary\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrb-ToOIFd_L",
        "outputId": "b8c7b0d8-1a55-4c1e-f55e-f7fbb258b8cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+---------+-----------+--------------+\n",
            "|EmpID|  Name| Department|TotalDays|PresentDays|AttendanceRate|\n",
            "+-----+------+-----------+---------+-----------+--------------+\n",
            "|    2|   Raj|Engineering|        2|          1|          50.0|\n",
            "|    5| Nisha|         HR|        2|          2|         100.0|\n",
            "|    1| Anita|         HR|        2|          2|         100.0|\n",
            "|    4| Aamir|  Marketing|        2|          0|           0.0|\n",
            "|    3|Simran|Engineering|        2|          2|         100.0|\n",
            "+-----+------+-----------+---------+-----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save it as Parquet partitioned by Department .\n",
        "\n",
        "emp_attendance_summary.write.mode(\"overwrite\").partitionBy(\"Department\").parquet(\"/content/emp_attendance_summary_parquet\")"
      ],
      "metadata": {
        "id": "Da1jerV1FgIX"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}