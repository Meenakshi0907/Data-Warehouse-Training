{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "j7qP8PeS5bTd",
        "outputId": "b52211ee-ecfa-41dc-df30-2d65feb8eacf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ad5140fc7d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0fb27d698491:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PysparkAssessment1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        ".appName(\"PysparkAssessment1\")\\\n",
        ".getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Ingestion & Exploration\n",
        "# Load both CSV files with schema inference.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "customer_df = spark.read.csv('/content/drive/MyDrive/customers.csv',header= True,inferSchema=True)\n",
        "orders_df = spark.read.csv('/content/drive/MyDrive/orders.csv',header= True,inferSchema=True)\n",
        "customer_df.show(5)\n",
        "orders_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtAJ7rW-7DN-",
        "outputId": "8a45b609-c56c-4900-8acd-8f38a463f663"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all columns and data types.\n",
        "\n",
        "print(\"Customers Schema:\")\n",
        "customer_df.printSchema()\n",
        "\n",
        "print(\"Orders Schema:\")\n",
        "orders_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UMlriMr8Gpe",
        "outputId": "6ad01946-068f-4c49-b098-1a372dc7915b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers Schema:\n",
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- SignupDate: date (nullable = true)\n",
            "\n",
            "Orders Schema:\n",
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of customers and orders.\n",
        "\n",
        "total_customers = customer_df.count()\n",
        "total_orders = orders_df.count()\n",
        "\n",
        "print(\"Total number of customers:\",total_customers)\n",
        "print(\"Total number of orders:\",total_orders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVJx_GlX8lDE",
        "outputId": "efbe0c4c-3b87-4250-b872-07946bb88cac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of customers: 5\n",
            "Total number of orders: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show distinct cities.\n",
        "\n",
        "dis_city = customer_df.select(\"City\").distinct()\n",
        "dis_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVkQc97J9Cog",
        "outputId": "ab6d97f1-c2a4-4d9b-eb24-5c1819a4642a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|     City|\n",
            "+---------+\n",
            "|Bangalore|\n",
            "|  Chennai|\n",
            "|   Mumbai|\n",
            "|    Delhi|\n",
            "|Hyderabad|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame Transformations\n",
        "# Add a column TotalAmount = Price * Quantity\n",
        "\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\",orders_df[\"Price\"] * orders_df[\"Quantity\"])\n",
        "orders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHp_vL1s9dMr",
        "outputId": "6e607280-9bfa-432d-899a-23a45cc14a05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column OrderYear from OrderDate .\n",
        "\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "orders_df = orders_df.withColumn(\"OrderYear\",year(orders_df['OrderDate']))\n",
        "orders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb80vd4B-K5G",
        "outputId": "c42d0dcb-eb07-424a-e95f-3de09f89cd13"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter orders with TotalAmount > 10,000 .\n",
        "\n",
        "gratervalue = orders_df.filter(orders_df['TotalAmount'] > 10000)\n",
        "gratervalue.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp5nBgH5-t0b",
        "outputId": "d864ab57-3e36-4c83-bc05-09071c7ea108"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the Email column from customers .\n",
        "\n",
        "customer_df = customer_df.drop('Email')\n",
        "customer_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3CYi4xA_Pt3",
        "outputId": "1ffcdc36-b759-45f6-c382-75c115796806"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+----------+\n",
            "|CustomerID| Name|     City|SignupDate|\n",
            "+----------+-----+---------+----------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|\n",
            "|       102| Neha|    Delhi|2023-01-15|\n",
            "|       103| Ravi|Bangalore|2021-11-01|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|\n",
            "|       105| Amit|  Chennai|2023-03-10|\n",
            "+----------+-----+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Nulls & Conditionals\n",
        "# Simulate a null in City and fill it with “Unknown”.\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "customer_df = customer_df.withColumn(\"City\",when(customer_df['CustomerID'] == 103,None).otherwise(customer_df[\"City\"]))\n",
        "\n",
        "customer_df = customer_df.fillna({\"City\":\"Unknown\"})\n",
        "customer_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3kivFm-_aif",
        "outputId": "b33b56d5-7dc0-4f75-f1cc-519d209bad9d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+----------+\n",
            "|CustomerID| Name|     City|SignupDate|\n",
            "+----------+-----+---------+----------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|\n",
            "|       102| Neha|    Delhi|2023-01-15|\n",
            "|       103| Ravi|  Unknown|2021-11-01|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|\n",
            "|       105| Amit|  Chennai|2023-03-10|\n",
            "+----------+-----+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label customers as “Loyal” if SignupDate is before 2022, else “New”.\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "customer_df = customer_df.withColumn(\"CustomerLable\",when(customer_df[\"SignupDate\"] < \"2022-01-01\",\"Loyal\").otherwise(\"New\"))\n",
        "customer_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rn-al_rAe5r",
        "outputId": "42fe6a85-964d-44bf-e3c9-52ba75dc5677"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+----------+-------------+\n",
            "|CustomerID| Name|     City|SignupDate|CustomerLable|\n",
            "+----------+-----+---------+----------+-------------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|          New|\n",
            "|       102| Neha|    Delhi|2023-01-15|          New|\n",
            "|       103| Ravi|  Unknown|2021-11-01|        Loyal|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|        Loyal|\n",
            "|       105| Amit|  Chennai|2023-03-10|          New|\n",
            "+----------+-----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create OrderType column: \"Low\" if < 5,000, \"High\" if >5,000.\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "orders_df = orders_df.withColumn(\"OrderType\",when(orders_df['Price'] < 5000,\"Low\").otherwise(\"High\"))\n",
        "orders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3NTwDxLB49d",
        "outputId": "b65451de-7a0b-4dbc-ecf8-62c2c61071ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|      Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joins & Aggregations\n",
        "# Join customers and orders on CustomerID .\n",
        "\n",
        "joined_df = orders_df.join(customer_df,on = \"CustomerID\",how = \"inner\")\n",
        "joined_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlu56zOADIoX",
        "outputId": "2b61c948-24eb-44e0-de07-2b001f2402ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+-----+---------+----------+-------------+\n",
            "|CustomerID|OrderID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType| Name|     City|SignupDate|CustomerLable|\n",
            "+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+-----+---------+----------+-------------+\n",
            "|       101|      1|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|  Ali|   Mumbai|2022-05-10|          New|\n",
            "|       101|      2|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|  Ali|   Mumbai|2022-05-10|          New|\n",
            "|       102|      3|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High| Neha|    Delhi|2023-01-15|          New|\n",
            "|       103|      4|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low| Ravi|  Unknown|2021-11-01|        Loyal|\n",
            "|       104|      5|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|Sneha|Hyderabad|2020-07-22|        Loyal|\n",
            "|       105|      6| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|      Low| Amit|  Chennai|2023-03-10|          New|\n",
            "|       102|      7|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High| Neha|    Delhi|2023-01-15|          New|\n",
            "+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+-----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total orders and revenue per city.\n",
        "from pyspark.sql.functions import count, sum\n",
        "\n",
        "city_total = joined_df.groupBy(\"City\").agg(count(\"OrderID\"),sum(\"TotalAmount\"))\n",
        "city_total.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeotNnpsEdr4",
        "outputId": "cdc6a0ab-23e5-400c-b40b-cbef979412bd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+----------------+\n",
            "|     City|count(OrderID)|sum(TotalAmount)|\n",
            "+---------+--------------+----------------+\n",
            "|  Chennai|             1|          2500.0|\n",
            "|   Mumbai|             2|        101200.0|\n",
            "|  Unknown|             1|          3500.0|\n",
            "|    Delhi|             2|         50000.0|\n",
            "|Hyderabad|             1|          5000.0|\n",
            "+---------+--------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show top 3 customers by total spend.\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "top_3_customer = joined_df.groupBy(\"CustomerID\",\"Name\").agg(sum(\"TotalAmount\").alias(\"TotalSpent\")).orderBy(col(\"TotalSpent\").desc()).limit(3)\n",
        "top_3_customer.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrLqUUvcFb0I",
        "outputId": "a7b2d2e4-e36f-4e12-b47b-9ad78b959053"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+----------+\n",
            "|CustomerID| Name|TotalSpent|\n",
            "+----------+-----+----------+\n",
            "|       101|  Ali|  101200.0|\n",
            "|       102| Neha|   50000.0|\n",
            "|       104|Sneha|    5000.0|\n",
            "+----------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many products each category has sold.\n",
        "\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "category_sold = joined_df.groupBy(\"Category\").agg(sum(\"Quantity\").alias(\"TotalProductSold\"))\n",
        "category_sold.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DyaIuZTGvKx",
        "outputId": "49ca2a7e-5ddc-4ff3-e768-b66805e94a1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------------+\n",
            "|   Category|TotalProductSold|\n",
            "+-----------+----------------+\n",
            "| Stationery|               5|\n",
            "|Electronics|               5|\n",
            "|  Furniture|               1|\n",
            "| Appliances|               1|\n",
            "+-----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark SQL Tasks\n",
        "# Create database sales and switch to it.\n",
        "\n",
        "spark.sql(\"create database sales\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmepnlimIdyJ",
        "outputId": "e488b72a-0408-4b48-ae6a-2627381e64d2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save both datasets as tables in the sales database.\n",
        "\n",
        "customer_df.write.mode(\"overwrite\").saveAsTable(\"sales.customers\")\n",
        "orders_df.write.mode(\"overwrite\").saveAsTable(\"sales.orders\")"
      ],
      "metadata": {
        "id": "gftBEtBEIw-g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write SQL to:\n",
        "# List all orders by customers from “Delhi”.\n",
        "spark.sql(\"\"\"select o.*\n",
        "from sales.orders o\n",
        "join sales.customers c\n",
        "on o.CustomerID = c.CustomerID\n",
        "where c.city = 'Delhi'\"\"\").show()\n",
        "# Find average order value in each category.\n",
        "spark.sql(\"\"\"select category,avg(totalamount) from sales.orders group by category\"\"\").show()\n",
        "# Create a view monthly_orders with month-wise total amount.\n",
        "spark.sql(\"\"\"create or replace temp view monthly_orders as\n",
        "select date_format(OrderDate,'yyyy-mm') as month,\n",
        "sum(price*quantity) as TotalAmount from sales.orders\n",
        "group by date_format(OrderDate,'yyyy-mm')\"\"\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM monthly_orders\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl30Re9pJhf7",
        "outputId": "84f6df0d-b96d-432e-faab-9a0bae5c50b5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n",
            "+-----------+----------------+\n",
            "|   category|avg(totalamount)|\n",
            "+-----------+----------------+\n",
            "| Stationery|          2500.0|\n",
            "|Electronics|         37800.0|\n",
            "|  Furniture|          3500.0|\n",
            "| Appliances|          5000.0|\n",
            "+-----------+----------------+\n",
            "\n",
            "+-------+-----------+\n",
            "|  month|TotalAmount|\n",
            "+-------+-----------+\n",
            "|2024-00|   162200.0|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import truncate\n",
        "# String & Date Functions\n",
        "# Mask emails using regex (e.g., a***@gmail.com ).\n",
        "\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "masked_email = customer_df.withColumn(\"MaskedEmail\",regexp_replace(\"Email\",r\"(^.)([^@]+)(@.*)\", r\"\\1***\\3\"))\n",
        "masked_email.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glyl2LoONOsf",
        "outputId": "5dafb5bb-34d6-46cc-a663-73f034a7f0ff"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+-----------+\n",
            "|CustomerID|Name |Email            |City     |SignupDate|MaskedEmail|\n",
            "+----------+-----+-----------------+---------+----------+-----------+\n",
            "|101       |Ali  |ali@gmail.com    |Mumbai   |2022-05-10|1***3      |\n",
            "|102       |Neha |neha@yahoo.com   |Delhi    |2023-01-15|1***3      |\n",
            "|103       |Ravi |ravi@hotmail.com |Bangalore|2021-11-01|1***3      |\n",
            "|104       |Sneha|sneha@outlook.com|Hyderabad|2020-07-22|1***3      |\n",
            "|105       |Amit |amit@gmail.com   |Chennai  |2023-03-10|1***3      |\n",
            "+----------+-----+-----------------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate Name and City as “Name from City”.\n",
        "\n",
        "from pyspark.sql.functions import concat_ws\n",
        "\n",
        "name_city = customer_df.withColumn(\"NameWithColumn\",concat_ws(\"from\",customer_df[\"Name\"],customer_df[\"City\"]))\n",
        "name_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0xvroHdOzEe",
        "outputId": "3e04b2c3-353c-40b7-9545-349d687df924"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+------------------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|    NameWithColumn|\n",
            "+----------+-----+-----------------+---------+----------+------------------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|     AlifromMumbai|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|     NehafromDelhi|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01| RavifromBangalore|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|SnehafromHyderabad|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|   AmitfromChennai|\n",
            "+----------+-----+-----------------+---------+----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use datediff() to calculate customer age in days.\n",
        "\n",
        "from pyspark.sql.functions import current_date,date_diff\n",
        "\n",
        "customer_age_diff = customer_df.withColumn(\"AgeInDays\",date_diff(current_date(),customer_df[\"SignupDate\"]))\n",
        "customer_age_diff.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sGcG8XpP6Uf",
        "outputId": "2a12d0aa-cbab-4f34-e0f1-9c198a52b638"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+---------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|AgeInDays|\n",
            "+----------+-----+-----------------+---------+----------+---------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|     1126|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|      876|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01|     1316|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|     1783|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|      822|\n",
            "+----------+-----+-----------------+---------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract month name from OrderDate .\n",
        "\n",
        "from pyspark.sql.functions import date_format\n",
        "\n",
        "orders_with_month = orders_df.withColumn(\"OrderMonth\",date_format(\"OrderDate\",\"MMMM\"))\n",
        "orders_with_month.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTs_vgdvRMe1",
        "outputId": "fc4c4ec3-191d-4dc2-9e15-28efb156350e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+----------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|OrderMonth|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+----------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   January|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|   January|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|  February|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|  February|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|  February|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     March|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|     March|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UDFs and Complex Logic\n",
        "# Write a UDF to tag customers:\n",
        "# “Gold” if spend >50K, “Silver” if 10K–50K, “Bronze” if <10K.\n",
        "\n",
        "from pyspark.sql.functions import udf, sum, col\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def tag_customer(spend):\n",
        "  if spend > 50000:\n",
        "    return \"Gold\"\n",
        "  elif spend >= 10000:\n",
        "    return \"Silver\"\n",
        "  else:\n",
        "    return \"Bronze\"\n",
        "\n",
        "tag_udf = udf(tag_customer,StringType())\n",
        "\n",
        "# Write a UDF to shorten product names (first 3 letters + ...).\n",
        "\n",
        "customer_spend_df = orders_df.withColumn(\"Spend\", col(\"Price\") * col(\"Quantity\")) \\\n",
        "    .groupBy(\"CustomerID\").agg(sum(\"Spend\").alias(\"TotalSpend\"))\n",
        "\n",
        "customer_tagged_df = customer_spend_df.withColumn(\"Tier\", tag_udf(\"TotalSpend\"))\n",
        "customer_tagged_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Tgp_e_R2Ny",
        "outputId": "8978e6d4-b61a-4609-e687-b11535cba98e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+------+\n",
            "|CustomerID|TotalSpend|  Tier|\n",
            "+----------+----------+------+\n",
            "|       101|  101200.0|  Gold|\n",
            "|       103|    3500.0|Bronze|\n",
            "|       102|   50000.0|Silver|\n",
            "|       105|    2500.0|Bronze|\n",
            "|       104|    5000.0|Bronze|\n",
            "+----------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parquet & Views\n",
        "# Save the joined result as a Parquet file.\n",
        "joined_df.write.mode(\"overwrite\").parquet(\"output/joined_data.parquet\")"
      ],
      "metadata": {
        "id": "bagXDEXtTc-M"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read it back and verify schema.\n",
        "parquet_df = spark.read.parquet(\"output/joined_data.parquet\")\n",
        "\n",
        "parquet_df.printSchema()\n",
        "parquet_df.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP4cIC4XVhHu",
        "outputId": "b1639480-f6eb-4612-d858-d1aa227d8b99"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            " |-- TotalAmount: double (nullable = true)\n",
            " |-- OrderYear: integer (nullable = true)\n",
            " |-- OrderType: string (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- SignupDate: date (nullable = true)\n",
            " |-- CustomerLable: string (nullable = true)\n",
            "\n",
            "+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+-----+---------+----------+-------------+\n",
            "|CustomerID|OrderID|Product  |Category   |Quantity|Price  |OrderDate |TotalAmount|OrderYear|OrderType|Name |City     |SignupDate|CustomerLable|\n",
            "+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+-----+---------+----------+-------------+\n",
            "|101       |1      |Laptop   |Electronics|2       |50000.0|2024-01-10|100000.0   |2024     |High     |Ali  |Mumbai   |2022-05-10|New          |\n",
            "|101       |2      |Mouse    |Electronics|1       |1200.0 |2024-01-15|1200.0     |2024     |Low      |Ali  |Mumbai   |2022-05-10|New          |\n",
            "|102       |3      |Tablet   |Electronics|1       |20000.0|2024-02-01|20000.0    |2024     |High     |Neha |Delhi    |2023-01-15|New          |\n",
            "|103       |4      |Bookshelf|Furniture  |1       |3500.0 |2024-02-10|3500.0     |2024     |Low      |Ravi |Unknown  |2021-11-01|Loyal        |\n",
            "|104       |5      |Mixer    |Appliances |1       |5000.0 |2024-02-15|5000.0     |2024     |High     |Sneha|Hyderabad|2020-07-22|Loyal        |\n",
            "|105       |6      |Notebook |Stationery |5       |500.0  |2024-03-01|2500.0     |2024     |Low      |Amit |Chennai  |2023-03-10|New          |\n",
            "|102       |7      |Phone    |Electronics|1       |30000.0|2024-03-02|30000.0    |2024     |High     |Neha |Delhi    |2023-01-15|New          |\n",
            "+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+-----+---------+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and query a global temp view.\n",
        "parquet_df.createOrReplaceGlobalTempView(\"join_order_customer\")\n",
        "\n",
        "spark.sql(\"\"\"SELECT Name, Product, TotalAmount, City\n",
        "FROM global_temp.join_order_customer\n",
        "WHERE TotalAmount > 10000\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wccrhSEuWFnA",
        "outputId": "04b99ae7-5645-447c-e109-8f18297ede9f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+-----------+------+\n",
            "|Name|Product|TotalAmount|  City|\n",
            "+----+-------+-----------+------+\n",
            "| Ali| Laptop|   100000.0|Mumbai|\n",
            "|Neha| Tablet|    20000.0| Delhi|\n",
            "|Neha|  Phone|    30000.0| Delhi|\n",
            "+----+-------+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare performance between CSV read and Parquet read.\n",
        "\n",
        "import time\n",
        "\n",
        "# Time CSV read\n",
        "start_csv = time.time()\n",
        "csv_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/content/drive/MyDrive/orders.csv\")\n",
        "csv_df.count()\n",
        "end_csv = time.time()\n",
        "\n",
        "# Time Parquet read\n",
        "start_parquet = time.time()\n",
        "parquet_df = spark.read.parquet(\"output/joined_data.parquet\")\n",
        "parquet_df.count()\n",
        "end_parquet = time.time()\n",
        "\n",
        "print(f\"CSV Read Time: {end_csv - start_csv:.4f} seconds\")\n",
        "print(f\"Parquet Read Time: {end_parquet - start_parquet:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y8Ey93NWrGn",
        "outputId": "344adcbf-ca9f-4fda-936b-62ec51edd36a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Read Time: 1.7767 seconds\n",
            "Parquet Read Time: 0.8025 seconds\n"
          ]
        }
      ]
    }
  ]
}